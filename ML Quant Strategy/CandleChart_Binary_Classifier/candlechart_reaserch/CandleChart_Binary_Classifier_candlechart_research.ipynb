{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d05871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import FinanceDataReader as fdr\n",
    "        \n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "mpl.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import Image as Imgdisplay\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "\n",
    "from trend_labeling import seq_seq_trend\n",
    "from candlechart4ML import candlechart_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84df3fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutput(filepath):\n",
    "    if(Path(filepath)).is_file():\n",
    "        os.remove(filepath)\n",
    "    \n",
    "def csv_initiator(market, ticker, head_date, tail_date):\n",
    "    df = fdr.DataReader(ticker, head_date, tail_date, exchange=market)\n",
    "    \n",
    "    filedir = os.getcwd() + '\\\\dataset\\\\raw_data\\\\'\n",
    "    filename = \"{}_{}.csv\".format(market, ticker)    \n",
    "    filepath = filedir + filename\n",
    "    \n",
    "    if not os.path.exists(filedir):\n",
    "        os.makedirs(filedir)    \n",
    "    removeOutput(filepath)\n",
    "    df.to_csv(filepath)\n",
    "    \n",
    "    print(\"csv file saved as : {}\".format(filepath))\n",
    "    \n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2c2cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file saved as : C:\\Users\\SeungHyuck\\Documents\\github_remote\\AI-Trade\\ML Quant Strategy\\CandleChart_Binary_Classifier\\candlechart_reaserch\\dataset\\raw_data\\KRX_005930.csv\n",
      "Creating label . . .\n",
      "type : Sequence to Sequence\n",
      "sequence_length : 20, trend_sequence_length : 20, gap : 0\n",
      "Create label finished.\n",
      "Converting ohlc to candlestick\n",
      "Converting finished\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "market = 'KRX'\n",
    "ticker = '005930'\n",
    "seq_len = 20\n",
    "tre_len = 20\n",
    "head_date = '2000-01-01'\n",
    "tail_date = '2022-01-01'\n",
    "dimension = 60\n",
    "use_volume = False\n",
    "\n",
    "data_csv_path = csv_initiator(market, ticker, head_date, tail_date)\n",
    "label_set_path = seq_seq_trend(data_csv_path, seq_len=seq_len, tre_len=tre_len)\n",
    "candlechart_dir = candlechart_generator(data_csv_path, seq_len=seq_len, tre_len=tre_len, dimension=dimension, use_volume=use_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b994fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADwAAAA8CAIAAAC1nk4lAAABTklEQVR4nO2aWxLCIAxFoeP+txw/rIoQHklDCDVnnGprRy6XJNDaEDpA74QFHKsFcHDRYnRi0qboDnZEw/v1cwjFjmgCLlqGV1AAJDsZBkX3MSg6JtshytHQnMbztv6oejSSQZVMQVv0UHjp9gnCDcIDim3+3WpObUNOo/1odXEyzPBYm6GoaCtFo1YBTCUiLjKx8KxmR7BgKZGu04Q1gBqS4aE2Yg+thmp8ekoY0qtOk9eREjBFl1o1yyTf6Vh8UCGGiuglY07A1OQySq16xMoOJ9nF2dLpVPSSUOY0SnX6ascYNbFsUiw8NIdp+5iejtSsuaXTkqs8SkDT6n12kgWnydk7RfTstZ4Fp8m46CrlP1eX5iJ3GqGRk/wp/xC/tsN+UHhh4uGhhdrNmhjk4mNLpzPRdm8bpNzB6T8Gvu/5cycibOm0i94av3JBeAIIlTxpguhiEgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "image/png": {
       "height": 180,
       "width": 180
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imgdisplay(candlechart_dir + os.listdir(candlechart_dir)[0], height=180, width=180) # 생성된 캔들차트 샘플확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad5244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea35c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 캔들차트이미지를 데이터 셋으로\n",
    "# 한 픽셀의 RGB 값, 한 변의 픽셀 수는 dimension\n",
    "def image2dataarray(candlechart_dir):\n",
    "    symbol = candlechart_dir.split('\\\\')[-3]\n",
    "    imgs = list([])\n",
    "    for i in range(len(os.listdir(candlechart_dir))):\n",
    "        imgname = '{}-{}.png'.format(symbol, i)\n",
    "        im = Image.open(candlechart_dir+imgname)\n",
    "        pixels = list(im.getdata())\n",
    "        img = list([])\n",
    "        for pixel in pixels:\n",
    "            for j in range(3): # Excepting alpha value\n",
    "                img.append(pixel[j])\n",
    "        imgs.append(img)\n",
    "        # print(imgs)\n",
    "    return np.array(imgs)\n",
    "\n",
    "def label2dataarray(label_set_path):\n",
    "    label_array = list([])\n",
    "    with open(label_set_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            label = int(line.split(',')[-1])\n",
    "            label_array.append(label)\n",
    "        return np.array(label_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab1d3aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5389 5389\n"
     ]
    }
   ],
   "source": [
    "candle_array = image2dataarray(candlechart_dir)\n",
    "label_array = label2dataarray(label_set_path)\n",
    "print(len(candle_array), len(label_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7524035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = candle_array\n",
    "y_all = label_array\n",
    "\n",
    "slicer = int(0.9 * len(candle_array))\n",
    "\n",
    "X_train, y_train = X_all[:slicer], y_all[:slicer]\n",
    "X_test, y_test = X_all[slicer:], y_all[slicer:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d24b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The possible options for loss are ‘hinge’, ‘log’, ‘modified_huber’, ‘squared_hinge’, ‘perceptron’\n",
    "# or a regression loss: ‘squared_error’, ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’.\n",
    "\n",
    "my_cv = TimeSeriesSplit(n_splits=5).split(X_train)\n",
    "params = {\n",
    "    'sgc__loss'    : ['hinge'],\n",
    "    'sgc__penalty' : ['l1', 'l2'],\n",
    "    # 'sgc__epsilon' : [-100, -10, -1],\n",
    "    'sgc__alpha'   : [10, 100, 1000],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62119774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<generator object TimeSeriesSplit.split at 0x0000025B50BB8740>,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('sgc',\n",
       "                                        SGDClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'sgc__alpha': [10, 100, 1000], 'sgc__loss': ['hinge'],\n",
       "                         'sgc__penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_cla_pipe = Pipeline([\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"sgc\", SGDClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "sgd_cla = GridSearchCV(sgd_cla_pipe, param_grid=params, cv=my_cv, n_jobs=-1)\n",
    "sgd_cla.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c13862d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_16092/3970894284.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\SEUNGH~1\\AppData\\Local\\Temp/ipykernel_16092/3970894284.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print(\"best prediction: {0:.4f}\".for mat(sgd_cla.best_score_))\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameter :\\n\", sgd_cla.best_params_)\n",
    "print(\"best prediction: {0:.4f}\".for mat(sgd_cla.best_score_))\n",
    "print(\"train set score: {0:.7f}\".format(sgd_cla.score(X_train, y_train))) # 훈련세트 점수\n",
    "print(\" test set score: {0:.7f}\".format(sgd_cla.score(X_test, y_test))) # 검증세트 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b151591",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(sgd_cla.predict(X_test), return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "randf_cla = Pipeline([\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"randf\", RandomForestClassifier()),\n",
    "            ])\n",
    "randf_cla.fit(X_train, y_train)\n",
    "print(\"train_set score: \", randf_cla.score(X_train, y_train)) # 훈련세트 점수\n",
    "print(\"test_set score : \", randf_cla.score(X_test, y_test)) # 검증세트 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd4a82cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[235 304]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(randf_cla.predict(X_test), return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bcbe9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set score:  1.0\n",
      "test_set score :  0.7402597402597403\n"
     ]
    }
   ],
   "source": [
    "ada_cla = Pipeline([\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"ada\", AdaBoostClassifier()),\n",
    "            ])\n",
    "ada_cla.fit(X_train, y_train)\n",
    "print(\"train_set score: \", randf_cla.score(X_train, y_train)) # 훈련세트 점수\n",
    "print(\"test_set score : \", randf_cla.score(X_test, y_test)) # 검증세트 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3819aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[235 304]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(ada_cla.predict(X_test), return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f070026d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set score:  0.9237113402061856\n",
      "test_set score :  0.7291280148423006\n"
     ]
    }
   ],
   "source": [
    "svm_cla = Pipeline([\n",
    "                    (\"scaler\", StandardScaler()),\n",
    "                    (\"svc\", SVC()),\n",
    "            ])\n",
    "svm_cla.fit(X_train, y_train)\n",
    "print(\"train_set score: \", svm_cla.score(X_train, y_train)) # 훈련세트 점수\n",
    "print(\"test_set score : \", svm_cla.score(X_test, y_test)) # 검증세트 점수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85847a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[243 296]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(svm_cla.predict(X_test), return_counts=True)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f91f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
